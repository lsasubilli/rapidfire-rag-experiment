{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYgFOQUVoj9Q"
      },
      "source": [
        "# Retrieval-First RAG Experimentation on NFCorpus\n",
        "\n",
        "This notebook presents a controlled Retrieval-Augmented Generation (RAG)\n",
        "experiment using the public **NFCorpus** biomedical QA dataset.\n",
        "\n",
        "The goal is to understand how retrieval and chunking configurations\n",
        "impact ranking quality, system stability, and latency under realistic\n",
        "LLM context constraints.\n",
        "\n",
        "This notebook is designed to be:\n",
        "- Fully reproducible on free-tier Google Colab (T4 GPU)\n",
        "- Retrieval-first (no generation quality judging)\n",
        "- Focused on experimentation and tradeoffs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBwkN-RoFWUw"
      },
      "source": [
        "## Dataset: NFCorpus\n",
        "\n",
        "NFCorpus is a biomedical question-answering dataset containing:\n",
        "- Natural language medical questions\n",
        "- Relevant biomedical abstracts\n",
        "- Human-annotated relevance judgments (qrels)\n",
        "\n",
        "Why NFCorpus:\n",
        "- Dense, technical text (stress-tests chunking strategies)\n",
        "- Realistic QA retrieval workload\n",
        "- Public, well-known IR benchmark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss4mGvkzGJlF"
      },
      "source": [
        "## Experiment Goal\n",
        "\n",
        "Evaluate how RAG retrieval configurations affect:\n",
        "- Ranking quality (Precision, Recall, F1, NDCG@5, MRR)\n",
        "- System stability under LLM context limits\n",
        "- End-to-end processing time\n",
        "\n",
        "We focus on **retrieval-first optimization**, not generation quality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QrCdudTGLy9"
      },
      "source": [
        "## Hypothesis\n",
        "\n",
        "1. Smaller chunk sizes will improve ranking metrics by reducing\n",
        "   semantic dilution in dense biomedical text.\n",
        "2. Increasing retrieval depth improves recall but risks\n",
        "   exceeding the LLM context window.\n",
        "3. A stable RAG system must balance ranking quality with\n",
        "   prompt length constraints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC7LhWQEoj9Q"
      },
      "source": [
        "### Install and Initialize RapidFire AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUhtUm5goj9R",
        "outputId": "ca7b6bda-f2c1-4832-afb9-e17d80176530"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import rapidfireai\n",
        "    print(\"‚úÖ rapidfireai already installed\")\n",
        "except ImportError:\n",
        "    !pip install rapidfireai  # Takes 1 min\n",
        "    !rapidfireai init --evals # Takes 1 min"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33aQVsKsoj9R"
      },
      "source": [
        "### Import Rapidfire Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vzSbP70ItG12"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
        "\n",
        "from rapidfireai import Experiment\n",
        "from rapidfireai.evals.automl import List, RFLangChainRagSpec, RFvLLMModelConfig, RFPromptManager, RFGridSearch\n",
        "import re, json\n",
        "from typing import List as listtype, Dict, Any\n",
        "\n",
        "# NB: If you get \"AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\" from Colab, just rerun this cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJM82HhAoj9R"
      },
      "source": [
        "### Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "fa5c3b1a8f8a4a869ed36d0222f3d3f7",
            "6a9f421539e043ed9074ffee98f3e74c",
            "c7efceccb6164531a3a968c12c5f04cf",
            "fe1e5504170c4521a243b18bb28dab8e",
            "19bf31f253e94a0e93fa5f1ae940ea1b",
            "81a3326eb6b4460fa6ddd2d0b630703f",
            "2406dcf5f92844078684b9173ccb5c62",
            "be778bccf1ed4c3a80f981d8215baed5",
            "f30ec383c1804680a9bfb7e07c720700",
            "324cf6442b75486598675aef64e2f12d",
            "7be2dfff0eae469f84126c457930cf8c",
            "523a556e1fb34ecd804dd573c5ffcd72",
            "f07bd392e0fa48ea96139ca5022af3b9",
            "b4f3b2be0ef54c979b9fa1e74c38cf0d",
            "ec7394f7361f4a36908105546bbf5513",
            "9cfbb6117c474979a399218c22cadd58",
            "bda5d413f70c43f98bee52921429986e",
            "33f05f43ea984b19bf9059e7192f98f3",
            "cb875d10cdf747f5b066e77839afd543",
            "82f81071eaa84c50887cb179378b37ca",
            "49ef185a73ac4b1cab88e9e960349b93",
            "cb345132c48a4771b03b760de37ccdc9"
          ]
        },
        "id": "OXwslOIMoj9R",
        "outputId": "8fa0491f-211f-4105-8d77-6ab530a7470e"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "!pip -q install beir\n",
        "\n",
        "from beir import util\n",
        "from beir.datasets.data_loader import GenericDataLoader\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path.cwd()\n",
        "OUT_DIR = ROOT / \"datasets\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/nfcorpus.zip\"\n",
        "\n",
        "# Download + unzip (returns the extracted dataset folder path)\n",
        "extracted_path = Path(util.download_and_unzip(url, str(OUT_DIR)))\n",
        "print(\"Extracted to:\", extracted_path)\n",
        "\n",
        "# Find the folder that actually contains corpus.jsonl (handles nested nfcorpus/nfcorpus)\n",
        "corpus_jsonl = next(extracted_path.rglob(\"corpus.jsonl\"))\n",
        "DATASET_DIR = corpus_jsonl.parent\n",
        "print(\"Using data_folder:\", DATASET_DIR)\n",
        "\n",
        "loader = GenericDataLoader(data_folder=str(DATASET_DIR))\n",
        "corpus, queries, qrels = loader.load()\n",
        "\n",
        "print(\"\\nDataset stats:\")\n",
        "print(f\"Corpus documents: {len(corpus)}\")\n",
        "print(f\"Queries: {len(queries)}\")\n",
        "print(f\"Qrels: {sum(len(v) for v in qrels.values())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TagdQNYhoj9R"
      },
      "source": [
        "### Dataset Normalization\n",
        "\n",
        "RAG evaluation pipelines rely on **strict ID consistency** across all inputs.\n",
        "\n",
        "In particular, the following fields must refer to the **same identifiers**:\n",
        "- `queries.jsonl` ‚Üí `query_id`\n",
        "- `corpus.jsonl` ‚Üí `_id`\n",
        "- `qrels.tsv` ‚Üí `query_id`, `corpus_id`\n",
        "\n",
        "If any of these IDs are stored as strings while others are integers, joins and lookups can fail silently or cause downstream errors during indexing, retrieval, or evaluation.\n",
        "\n",
        "RapidFire AI expects **integer IDs** for queries and documents, since IDs are used internally for hashing, indexing, and metric computation.  \n",
        "This notebook includes a normalization step to ensure all dataset files use consistent integer IDs before running experiments.\n",
        "\n",
        "\n",
        "### Dataset normalization contract\n",
        "This notebook produces a canonical set of dataset files (*.final.*) that are guaranteed to use integer identifiers.\n",
        "\n",
        "If the source dataset already satisfies this constraint, files are copied unchanged. Otherwise, deterministic ID normalization is applied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ_pHTkUoj9R",
        "outputId": "9419f34d-fb3a-4bfa-eacb-89adc9d9b400"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "def prepare_final_dataset(\n",
        "    dataset_dir: Path,\n",
        "    corpus_file=\"corpus.jsonl\",\n",
        "    queries_file=\"queries.jsonl\",\n",
        "    qrels_file=\"qrels.tsv\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Produces canonical files:\n",
        "      - corpus.final.jsonl\n",
        "      - queries.final.jsonl\n",
        "      - qrels.final.tsv\n",
        "\n",
        "    Handles datasets where query IDs may be under `_id` or `query_id`.\n",
        "    \"\"\"\n",
        "\n",
        "    corpus_path = dataset_dir / corpus_file\n",
        "    queries_path = dataset_dir / queries_file\n",
        "    qrels_path = dataset_dir / qrels_file\n",
        "\n",
        "    final_corpus = dataset_dir / \"corpus.final.jsonl\"\n",
        "    final_queries = dataset_dir / \"queries.final.jsonl\"\n",
        "    final_qrels  = dataset_dir / \"qrels.final.tsv\"\n",
        "\n",
        "    # --------------------\n",
        "    # Load inputs\n",
        "    # --------------------\n",
        "    with open(corpus_path) as f:\n",
        "        corpus = [json.loads(l) for l in f]\n",
        "\n",
        "    with open(queries_path) as f:\n",
        "        queries = [json.loads(l) for l in f]\n",
        "\n",
        "    qrels = pd.read_csv(\n",
        "        qrels_path,\n",
        "        sep=\"\\t\",\n",
        "        header=None,\n",
        "        names=[\"query_id\", \"corpus_id\", \"relevance\"]\n",
        "    )\n",
        "\n",
        "    # --------------------\n",
        "    # Detect query ID field\n",
        "    # --------------------\n",
        "    if \"query_id\" in queries[0]:\n",
        "        query_id_key = \"query_id\"\n",
        "    elif \"_id\" in queries[0]:\n",
        "        query_id_key = \"_id\"\n",
        "    else:\n",
        "        raise ValueError(\"‚ùå Could not find query ID field in queries.jsonl\")\n",
        "\n",
        "    print(\"üîç ID type check\")\n",
        "    print(f\"  corpus _id: {type(corpus[0].get('_id'))}\")\n",
        "    print(f\"  query {query_id_key}: {type(queries[0].get(query_id_key))}\")\n",
        "\n",
        "    # --------------------\n",
        "    # Check if already normalized\n",
        "    # --------------------\n",
        "    if isinstance(corpus[0][\"_id\"], int) and isinstance(queries[0][query_id_key], int):\n",
        "        shutil.copy(corpus_path, final_corpus)\n",
        "        shutil.copy(queries_path, final_queries)\n",
        "        shutil.copy(qrels_path, final_qrels)\n",
        "        print(\"\\n‚úÖ IDs already integers ‚Äî copied originals to *.final.*\")\n",
        "        return\n",
        "\n",
        "    # --------------------\n",
        "    # Normalize IDs\n",
        "    # --------------------\n",
        "    print(\"\\n‚ö†Ô∏è String IDs detected. Normalizing deterministically...\")\n",
        "\n",
        "    corpus_id_map = {doc[\"_id\"]: i for i, doc in enumerate(corpus)}\n",
        "    query_id_map  = {q[query_id_key]: i for i, q in enumerate(queries)}\n",
        "\n",
        "    # Rewrite corpus\n",
        "    for doc in corpus:\n",
        "        doc[\"_id\"] = corpus_id_map[doc[\"_id\"]]\n",
        "\n",
        "    # Rewrite queries (canonicalize to query_id)\n",
        "    for q in queries:\n",
        "        q[\"query_id\"] = query_id_map[q[query_id_key]]\n",
        "        if query_id_key != \"query_id\":\n",
        "            del q[query_id_key]\n",
        "\n",
        "\n",
        "    # Rewrite qrels\n",
        "    qrels[\"query_id\"]  = qrels[\"query_id\"].map(query_id_map)\n",
        "    qrels[\"corpus_id\"] = qrels[\"corpus_id\"].map(corpus_id_map)\n",
        "\n",
        "    missing = qrels[qrels.isnull().any(axis=1)]\n",
        "    if len(missing) > 0:\n",
        "        print(f\"‚ö†Ô∏è Dropping {len(missing)} qrels with missing corpus/query IDs\")\n",
        "        qrels = qrels.dropna().reset_index(drop=True)\n",
        "\n",
        "    # --------------------\n",
        "    # Write canonical finals\n",
        "    # --------------------\n",
        "    with open(final_corpus, \"w\") as f:\n",
        "        for doc in corpus:\n",
        "            f.write(json.dumps(doc) + \"\\n\")\n",
        "\n",
        "    with open(final_queries, \"w\") as f:\n",
        "        for q in queries:\n",
        "            f.write(json.dumps(q) + \"\\n\")\n",
        "\n",
        "    qrels.to_csv(final_qrels, sep=\"\\t\", index=False, header=False)\n",
        "\n",
        "    print(\"\\n‚úÖ Normalization complete\")\n",
        "    print(\"‚û° Written canonical files:\")\n",
        "    print(\"   - corpus.final.jsonl\")\n",
        "    print(\"   - queries.final.jsonl\")\n",
        "    print(\"   - qrels.final.tsv\")\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "NF_DATASET_DIR = Path(\"/content/datasets/nfcorpus\")\n",
        "\n",
        "prepare_final_dataset(\n",
        "    dataset_dir=NF_DATASET_DIR,\n",
        "    corpus_file=\"corpus.jsonl\",\n",
        "    queries_file=\"queries.jsonl\",\n",
        "    qrels_file=\"qrels/test.tsv\",\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyPvUt8Loj9S"
      },
      "source": [
        "### Load Dataset, Rename Columns, and Downsample Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203,
          "referenced_widgets": [
            "3da4baecc76f4181937b5f4b7915230e",
            "6bd8f6b015684f91be777f221cff393c",
            "d28f9d6588bd4fc5b55df2ba8ea00188",
            "c426608648eb4f5380de412b0cd79eda",
            "54a90186865a4c5fbc53d65711b289fe",
            "98342115463b4c448b44f6f6c4e41350",
            "e44b4c1f0b9e49a48b279718b9787a42",
            "a1d671fa97d544a0ae13ff7250c04c27",
            "1cf4bdcc318e4c9b9696406f11749cfe",
            "550cba4136294729afb26f7c45ed4546",
            "1332661b33f24d9fb45b24680d2a9ef8",
            "335d0d7401304b0289517459ac45542b",
            "0ec0c71ba59f49369d6ba23037894e6d",
            "cef2edaff4b84bddb1a9c537e3b20a17",
            "001a35e834c641ae9046aef17cc8b409",
            "29b9321854e84566b585f87c9890764c",
            "645935857b124be2b7b2a7b615cd0710",
            "36f3fc682e014b9cbb642109788c72d3",
            "5fbab41b511f43e1938b56d599f099c3",
            "e0ba8e0ae136468ba12ee980df98674a",
            "1d454cc0265446c9bc6aa2c0d39a24f8",
            "1bebaedd7e3a45f3a9c92b7def9db33f"
          ]
        },
        "id": "c1F9DNpKtKn5",
        "outputId": "c086f809-020d-4036-9bac-f1d922adf4fd"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import json, random\n",
        "from pathlib import Path\n",
        "\n",
        "# ----------------\n",
        "# Project + dataset root\n",
        "# ----------------\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "dataset_dir = PROJECT_ROOT / \"datasets\" / \"nfcorpus\"\n",
        "\n",
        "# ----------------\n",
        "# Load queries (canonical final)\n",
        "# ----------------\n",
        "nfcorpus_dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=str(dataset_dir / \"queries.final.jsonl\"),\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "# Rename only if needed\n",
        "if \"text\" in nfcorpus_dataset.column_names:\n",
        "    nfcorpus_dataset = nfcorpus_dataset.rename_columns({\"text\": \"query\"})\n",
        "\n",
        "# ----------------\n",
        "# Load qrels (canonical final)\n",
        "# ----------------\n",
        "qrels = pd.read_csv(\n",
        "    dataset_dir / \"qrels.final.tsv\",\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    names=[\"query_id\", \"corpus_id\", \"relevance\"]\n",
        ")\n",
        "\n",
        "\n",
        "# ----------------\n",
        "# Downsample queries + corpus jointly (NFCorpus-safe)\n",
        "# ----------------\n",
        "NUM_QUERIES = 10\n",
        "rseed = 1\n",
        "\n",
        "# Keep only queries that have qrels\n",
        "valid_query_ids = set(qrels[\"query_id\"].unique())\n",
        "\n",
        "nfcorpus_dataset = nfcorpus_dataset.filter(\n",
        "    lambda x: x[\"query_id\"] in valid_query_ids\n",
        ")\n",
        "\n",
        "print(f\"Queries with qrels: {len(nfcorpus_dataset)}\")\n",
        "\n",
        "nfcorpus_dataset = (\n",
        "    nfcorpus_dataset\n",
        "    .shuffle(seed=rseed)\n",
        "    .select(range(min(NUM_QUERIES, len(nfcorpus_dataset))))\n",
        ")\n",
        "\n",
        "print(f\"Using {len(nfcorpus_dataset)} queries\")\n",
        "\n",
        "# IDs are guaranteed to be integers\n",
        "query_ids = set(nfcorpus_dataset[\"query_id\"])\n",
        "\n",
        "# Step 2: Filter qrels to sampled queries\n",
        "qrels_filtered = qrels[qrels[\"query_id\"].isin(query_ids)]\n",
        "relevant_corpus_ids = set(qrels_filtered[\"corpus_id\"].tolist())\n",
        "\n",
        "print(f\"Using {len(nfcorpus_dataset)} queries\")\n",
        "print(f\"Found {len(relevant_corpus_ids)} relevant documents for these queries\")\n",
        "\n",
        "# ----------------\n",
        "# Step 3: Load corpus (canonical final) and filter\n",
        "# ----------------\n",
        "input_file = dataset_dir / \"corpus.final.jsonl\"\n",
        "output_file = dataset_dir / \"corpus_sampled.jsonl\"\n",
        "\n",
        "with open(input_file, \"r\") as f:\n",
        "    all_corpus = [json.loads(line) for line in f]\n",
        "\n",
        "sampled_corpus = [\n",
        "    doc for doc in all_corpus\n",
        "    if doc[\"_id\"] in relevant_corpus_ids\n",
        "]\n",
        "\n",
        "with open(output_file, \"w\") as f:\n",
        "    for doc in sampled_corpus:\n",
        "        f.write(json.dumps(doc) + \"\\n\")\n",
        "\n",
        "print(f\"Sampled {len(sampled_corpus)} documents from {len(all_corpus)} total\")\n",
        "print(f\"Saved to: {output_file}\")\n",
        "print(f\"Filtered qrels to {len(qrels_filtered)} relevance judgments\")\n",
        "\n",
        "# Update qrels to match sampled dataset\n",
        "qrels = qrels_filtered.reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slsn9yJXJVuu"
      },
      "source": [
        "## Experiment Design\n",
        "\n",
        "### Fixed Parameters\n",
        "- Dataset: NFCorpus\n",
        "- Embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
        "- Vector index: FAISS (default)\n",
        "- Retrieval method: similarity search\n",
        "- Reranker: cross-encoder/ms-marco-MiniLM-L6-v2\n",
        "- LLM: Qwen/Qwen2.5-0.5B-Instruct (3000 token context)\n",
        "\n",
        "### Varied Parameters\n",
        "- Chunk size ‚àà {128, 256}\n",
        "- Retrieval depth (k) ‚àà {8, 16}\n",
        "- Reranker top_n ‚àà {2}\n",
        "\n",
        "### Metrics\n",
        "- Precision\n",
        "- Recall\n",
        "- F1 Score\n",
        "- NDCG@5\n",
        "- MRR\n",
        "- Processing time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecFDB_b7oj9S"
      },
      "source": [
        "\n",
        "\n",
        "### Create Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "4xxYEoqAtj28",
        "outputId": "e0c12b83-7d7e-4e58-a6d0-644feeecec3e"
      },
      "outputs": [],
      "source": [
        "experiment = Experiment(experiment_name=\"exp1-nfcorpus-rag-colab\", mode=\"evals\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYm0yHrqoj9S"
      },
      "source": [
        "### Define Partial Multi-Config Knobs for LangChain part of RAG Pipeline using RapidFire AI Wrapper APIs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "n529qQVgtpta"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader, JSONLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_classic.retrievers.document_compressors import CrossEncoderReranker\n",
        "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
        "\n",
        "# Per-Actor batch size for hardware efficiency\n",
        "batch_size = 50\n",
        "\n",
        "# 2 chunk sizes x 2 reranking top-n = 4 combinations in total\n",
        "rag_gpu = RFLangChainRagSpec(\n",
        "    document_loader=DirectoryLoader(\n",
        "        path=str(NF_DATASET_DIR),\n",
        "\n",
        "        glob=\"corpus.final.jsonl\",\n",
        "        loader_cls=JSONLoader,\n",
        "        loader_kwargs={\n",
        "            \"jq_schema\": \".\",\n",
        "            \"content_key\": \"text\",\n",
        "            \"metadata_func\": lambda record, metadata: {\n",
        "                \"corpus_id\": int(record.get(\"_id\"))\n",
        "            },  # store the document id\n",
        "            \"json_lines\": True,\n",
        "            \"text_content\": False,\n",
        "        },\n",
        "        sample_seed=42,\n",
        "    ),\n",
        "    # 2 chunking strategies with different chunk sizes\n",
        "    text_splitter=List([\n",
        "            RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "                encoding_name=\"gpt2\", chunk_size=256, chunk_overlap=32\n",
        "            ),\n",
        "            RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "                encoding_name=\"gpt2\", chunk_size=128, chunk_overlap=32\n",
        "            ),\n",
        "            # RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "            #     encoding_name=\"gpt2\", chunk_size=64, chunk_overlap=32\n",
        "            # ),\n",
        "        ],\n",
        "    ),\n",
        "    embedding_cls=HuggingFaceEmbeddings,\n",
        "    embedding_kwargs={\n",
        "        \"model_name\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "        \"model_kwargs\": {\"device\": \"cuda:0\"},\n",
        "        \"encode_kwargs\": {\"normalize_embeddings\": True, \"batch_size\": batch_size},\n",
        "    },\n",
        "    vector_store=None,  # uses FAISS by default\n",
        "    search_type=\"similarity\",\n",
        "    #search_kwargs={\"k\": 8},\n",
        "    search_kwargs={\"k\": List([8, 16])},\n",
        "    # 2 reranking strategies with different top-n values\n",
        "    reranker_cls=CrossEncoderReranker,\n",
        "    reranker_kwargs={\n",
        "        \"model_name\": \"cross-encoder/ms-marco-MiniLM-L6-v2\",\n",
        "        \"model_kwargs\": {\"device\": \"cpu\"},\n",
        "        \"top_n\": List([2]),\n",
        "        #\"top_n\": List([2, 5]),\n",
        "    },\n",
        "    enable_gpu_search=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qTlw5QhMkpa"
      },
      "source": [
        "## Context Length Constraints\n",
        "\n",
        "We observed that increasing chunk_size to 256 caused prompt overflow,\n",
        "even when limiting reranked context to top_n=2.\n",
        "\n",
        "This occurs because:\n",
        "- Biomedical abstracts are dense\n",
        "- Larger chunks increase prompt length rapidly\n",
        "- The Qwen2.5-0.5B model has a 3000 token limit\n",
        "\n",
        "As a result, **chunk_size=256 combined with deep retrieval (rag_k=16) fails deterministically**.  \n",
        "However, `chunk_size=256` with moderate retrieval depth (`rag_k=8`) remains stable and achieves strong ranking quality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-GeYEKNoj9T"
      },
      "source": [
        "### Define Data Processing and Postprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfYsHjKfuuJJ"
      },
      "outputs": [],
      "source": [
        "def sample_preprocess_fn(\n",
        "    batch: Dict[str, listtype], rag: RFLangChainRagSpec, prompt_manager: RFPromptManager\n",
        ") -> Dict[str, listtype]:\n",
        "    \"\"\"Function to prepare the final inputs given to the generator model\"\"\"\n",
        "\n",
        "    INSTRUCTIONS = \"Use the provided biomedical context to answer the question accurately.\"\n",
        "\n",
        "\n",
        "    # Perform batched retrieval over all queries; returns a list of lists of k documents per query\n",
        "    all_context = rag.get_context(batch_queries=batch[\"query\"], serialize=False)\n",
        "\n",
        "    # Extract the retrieved document ids from the context\n",
        "    retrieved_documents = [\n",
        "        [doc.metadata[\"corpus_id\"] for doc in docs] for docs in all_context\n",
        "    ]\n",
        "\n",
        "    # Serialize the retrieved documents into a single string per query using the default template\n",
        "    serialized_context = rag.serialize_documents(all_context)\n",
        "    batch[\"query_id\"] = [int(query_id) for query_id in batch[\"query_id\"]]\n",
        "\n",
        "    # Each batch to contain conversational prompt, retrieved documents, and original 'query_id', 'query', 'metadata'\n",
        "    return {\n",
        "        \"prompts\": [\n",
        "            [\n",
        "                {\"role\": \"system\", \"content\": INSTRUCTIONS},\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"Here is some relevant context:\\n{context}. \\nNow answer the following question using the context provided earlier:\\n{question}\",\n",
        "                },\n",
        "            ]\n",
        "            for question, context in zip(batch[\"query\"], serialized_context)\n",
        "        ],\n",
        "        \"retrieved_documents\": retrieved_documents,\n",
        "        **batch,\n",
        "    }\n",
        "\n",
        "\n",
        "def sample_postprocess_fn(batch: Dict[str, listtype]) -> Dict[str, listtype]:\n",
        "    \"\"\"Function to postprocess outputs produced by generator model\"\"\"\n",
        "    # Get ground truth documents for each query; can be done in preprocess_fn too but done here for clarity\n",
        "    batch[\"ground_truth_documents\"] = [\n",
        "        qrels[qrels[\"query_id\"] == query_id][\"corpus_id\"].tolist()\n",
        "        for query_id in batch[\"query_id\"]\n",
        "    ]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCTvaA7ioj9T"
      },
      "source": [
        "### Define Custom Eval Metrics Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YotlVN-6u5Je"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def compute_ndcg_at_k(retrieved_docs: set, expected_docs: set, k=5):\n",
        "    \"\"\"Utility function to compute NDCG@k\"\"\"\n",
        "    relevance = [1 if doc in expected_docs else 0 for doc in list(retrieved_docs)[:k]]\n",
        "    dcg = sum(rel / math.log2(i + 2) for i, rel in enumerate(relevance))\n",
        "\n",
        "    # IDCG: perfect ranking limited by min(k, len(expected_docs))\n",
        "    ideal_length = min(k, len(expected_docs))\n",
        "    ideal_relevance = [3] * ideal_length + [0] * (k - ideal_length)\n",
        "    idcg = sum(rel / math.log2(i + 2) for i, rel in enumerate(ideal_relevance))\n",
        "\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "\n",
        "def compute_rr(retrieved_docs: set, expected_docs: set):\n",
        "    \"\"\"Utility function to compute Reciprocal Rank (RR) for a single query\"\"\"\n",
        "    rr = 0\n",
        "    for i, retrieved_doc in enumerate(retrieved_docs):\n",
        "        if retrieved_doc in expected_docs:\n",
        "            rr = 1 / (i + 1)\n",
        "            break\n",
        "    return rr\n",
        "\n",
        "\n",
        "def sample_compute_metrics_fn(batch: Dict[str, listtype]) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"Function to compute all eval metrics based on retrievals and/or generations\"\"\"\n",
        "\n",
        "    true_positives, precisions, recalls, f1_scores, ndcgs, rrs = 0, [], [], [], [], []\n",
        "    total_queries = len(batch[\"query\"])\n",
        "\n",
        "    for pred, gt in zip(batch[\"retrieved_documents\"], batch[\"ground_truth_documents\"]):\n",
        "        expected_set = set(gt)\n",
        "        retrieved_set = set(pred)\n",
        "\n",
        "        true_positives = len(expected_set.intersection(retrieved_set))\n",
        "        precision = true_positives / len(retrieved_set) if len(retrieved_set) > 0 else 0\n",
        "        recall = true_positives / len(expected_set) if len(expected_set) > 0 else 0\n",
        "        f1 = (\n",
        "            2 * precision * recall / (precision + recall)\n",
        "            if (precision + recall) > 0\n",
        "            else 0\n",
        "        )\n",
        "\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "        ndcgs.append(compute_ndcg_at_k(retrieved_set, expected_set, k=5))\n",
        "        rrs.append(compute_rr(retrieved_set, expected_set))\n",
        "\n",
        "    return {\n",
        "        \"Total\": {\"value\": total_queries},\n",
        "        \"Precision\": {\"value\": sum(precisions) / total_queries},\n",
        "        \"Recall\": {\"value\": sum(recalls) / total_queries},\n",
        "        \"F1 Score\": {\"value\": sum(f1_scores) / total_queries},\n",
        "        \"NDCG@5\": {\"value\": sum(ndcgs) / total_queries},\n",
        "        \"MRR\": {\"value\": sum(rrs) / total_queries},\n",
        "    }\n",
        "\n",
        "\n",
        "def sample_accumulate_metrics_fn(\n",
        "    aggregated_metrics: Dict[str, listtype],\n",
        ") -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"Function to accumulate eval metrics across all batches\"\"\"\n",
        "\n",
        "    num_queries_per_batch = [m[\"value\"] for m in aggregated_metrics[\"Total\"]]\n",
        "    total_queries = sum(num_queries_per_batch)\n",
        "    algebraic_metrics = [\"Precision\", \"Recall\", \"F1 Score\", \"NDCG@5\", \"MRR\"]\n",
        "\n",
        "    return {\n",
        "        \"Total\": {\"value\": total_queries},\n",
        "        **{\n",
        "            metric: {\n",
        "                \"value\": sum(\n",
        "                    m[\"value\"] * queries\n",
        "                    for m, queries in zip(\n",
        "                        aggregated_metrics[metric], num_queries_per_batch\n",
        "                    )\n",
        "                )\n",
        "                / total_queries,\n",
        "                \"is_algebraic\": True,\n",
        "                \"value_range\": (0, 1),\n",
        "            }\n",
        "            for metric in algebraic_metrics\n",
        "        },\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUdedKP_oj9T"
      },
      "source": [
        "### Define Partial Multi-Config Knobs for vLLM Generator part of RAG Pipeline using RapidFire AI Wrapper APIs\n",
        "\n",
        "This tutorial showcases Qwen2.5-0.5B-Instruct (0.5B parameters), which is perfect for Colab's memory constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "joW5Pgr0u6sX"
      },
      "outputs": [],
      "source": [
        "vllm_config1 = RFvLLMModelConfig(\n",
        "    model_config={\n",
        "        \"model\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
        "        \"dtype\": \"half\",\n",
        "        \"gpu_memory_utilization\": 0.25,\n",
        "        \"tensor_parallel_size\": 1,\n",
        "        \"distributed_executor_backend\": \"mp\",\n",
        "        \"enable_chunked_prefill\": False,\n",
        "        \"enable_prefix_caching\": False,\n",
        "        \"max_model_len\": 3000,\n",
        "        \"disable_log_stats\": True,  # Disable vLLM progress logging\n",
        "        \"enforce_eager\": True,\n",
        "        \"disable_custom_all_reduce\": True,\n",
        "    },\n",
        "    sampling_params={\n",
        "        \"temperature\": 0.8,\n",
        "        \"top_p\": 0.95,\n",
        "        \"max_tokens\": 128,\n",
        "    },\n",
        "    rag=rag_gpu,\n",
        "    prompt_manager=None,\n",
        ")\n",
        "\n",
        "batch_size = 3 # Smaller batch size for generation\n",
        "config_set = {\n",
        "    \"vllm_config\": vllm_config1,  # Only 1 generator, but it represents 4 full configs\n",
        "    \"batch_size\": batch_size,\n",
        "    \"preprocess_fn\": sample_preprocess_fn,\n",
        "    \"postprocess_fn\": sample_postprocess_fn,\n",
        "    \"compute_metrics_fn\": sample_compute_metrics_fn,\n",
        "    \"accumulate_metrics_fn\": sample_accumulate_metrics_fn,\n",
        "    \"online_strategy_kwargs\": {\n",
        "        \"strategy_name\": \"normal\",\n",
        "        \"confidence_level\": 0.95,\n",
        "        \"use_fpc\": True,\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBhf0aKwoj9T"
      },
      "source": [
        "### Create Config Group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2-bJ2gYnvABU"
      },
      "outputs": [],
      "source": [
        "# Simple grid search across all config combinations: 4 total (2 chunkers √ó 2 rerankers)\n",
        "config_group = RFGridSearch(config_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p78NwcfPoj9T"
      },
      "source": [
        "### Run Multi-Config Evals + Launch Interactive Run Controller\n",
        "\n",
        "Now we get to the main function for running multi-config evals. Two tables will appear below the run_evals cell:\n",
        "- The first table will appear immediately. It lists all preprocessing/RAG sources.\n",
        "- After a short while, the second table will appear. It lists all individual runs with their knobs and metrics that are updated in real-time via online aggregation showing both estimates and confidence intervals.\n",
        "\n",
        "RapidFire AI also provides an Interactive Controller panel UI for Colab that lets you manage executing runs dynamically in real-time from the notebook:\n",
        "\n",
        "- ‚èπÔ∏è **Stop**: Gracefully stop a running config\n",
        "- ‚ñ∂Ô∏è **Resume**: Resume a stopped run\n",
        "- üóëÔ∏è **Delete**: Remove a run from this experiment\n",
        "- üìã **Clone**: Create a new run by editing the config dictionary of a parent run to try new knob values; optional warm start of parameters\n",
        "- üîÑ **Refresh**: Update run status and metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPwGpCGSvGLp"
      },
      "outputs": [],
      "source": [
        "# Launch evals of all RAG configs in the config_group with swap granularity of 4 chunks\n",
        "# NB: If your machine has more than 1 GPU, set num_actors to that number\n",
        "results = experiment.run_evals(\n",
        "    config_group=config_group,\n",
        "    dataset=nfcorpus_dataset,\n",
        "    num_actors=1,\n",
        "    num_shards=4,\n",
        "    seed=42,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7L1YN1Koj9T"
      },
      "source": [
        "### View Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBxi0R-nvKRP"
      },
      "outputs": [],
      "source": [
        "# Convert results dict to DataFrame\n",
        "results_df = pd.DataFrame([\n",
        "    {k: v['value'] if isinstance(v, dict) and 'value' in v else v for k, v in {**metrics_dict, 'run_id': run_id}.items()}\n",
        "    for run_id, (_, metrics_dict) in results.items()\n",
        "])\n",
        "\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF1u0wEDNACg"
      },
      "source": [
        "## Result Interpretation\n",
        "\n",
        "Key observations:\n",
        "- chunk_size=128 provides stable execution across all runs\n",
        "- Larger chunks improve recall marginally but fail due to context overflow\n",
        "- Increasing retrieval depth (rag_k=16) improves recall but introduces mild precision and ranking tradeoffs, \n",
        "  especially when combined with larger chunks.\n",
        "\n",
        "- Reranking with top_n=2 provides the best balance of quality and stability\n",
        "\n",
        "This confirms the hypothesis that chunk size dominates RAG stability\n",
        "for dense biomedical datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OUWSck_oj9U"
      },
      "source": [
        "### End Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLZGBBM8vNjl"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "display(HTML('''\n",
        "<button id=\"continue-btn\" style=\"padding: 10px 20px; font-size: 16px;\">Click to End Experiment</button>\n",
        "'''))\n",
        "\n",
        "# eval_js blocks until the Promise resolves\n",
        "output.eval_js('''\n",
        "new Promise((resolve) => {\n",
        "    document.getElementById(\"continue-btn\").onclick = () => {\n",
        "        document.getElementById(\"continue-btn\").disabled = true;\n",
        "        document.getElementById(\"continue-btn\").innerText = \"Continuing...\";\n",
        "        resolve(\"clicked\");\n",
        "    };\n",
        "})\n",
        "''')\n",
        "\n",
        "# Actually end the experiment after the button is clicked\n",
        "experiment.end()\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY8l99S6oj9U"
      },
      "source": [
        "### View RapidFire AI Log Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFWA50drvRy0"
      },
      "outputs": [],
      "source": [
        "# Get the experiment-specific log file\n",
        "log_file = experiment.get_log_file_path()\n",
        "\n",
        "print(f\"üìÑ Log File: {log_file}\")\n",
        "print()\n",
        "\n",
        "if log_file.exists():\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Last 30 lines of {log_file.name}:\")\n",
        "    print(\"=\" * 80)\n",
        "    with open(log_file, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "        for line in lines[-30:]:\n",
        "            print(line.rstrip())\n",
        "else:\n",
        "    print(f\"‚ùå Log file not found: {log_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPqXtmz2oj9U"
      },
      "source": [
        "### Plot the Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIbnL01l7YbW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# ----------------------------------\n",
        "# Normalize Processing Time safely\n",
        "# ----------------------------------\n",
        "results_df = results_df.copy()\n",
        "\n",
        "results_df[\"Processing Time\"] = (\n",
        "    results_df[\"Processing Time\"]\n",
        "    .astype(str)\n",
        "    .str.replace(\" seconds\", \"\", regex=False)\n",
        "    .astype(float)\n",
        ")\n",
        "\n",
        "# ----------------------------------\n",
        "# Prepare plotting dataframe\n",
        "# ----------------------------------\n",
        "plot_df = results_df[\n",
        "    [\n",
        "        \"chunk_size\",\n",
        "        \"rag_k\",\n",
        "        \"Precision\",\n",
        "        \"Recall\",\n",
        "        \"F1 Score\",\n",
        "        \"NDCG@5\",\n",
        "        \"MRR\",\n",
        "        \"Processing Time\",\n",
        "    ]\n",
        "].copy()\n",
        "\n",
        "# Force numeric where possible (safe, no hardcoding)\n",
        "for col in [\"Precision\", \"Recall\", \"F1 Score\", \"NDCG@5\", \"MRR\", \"Processing Time\"]:\n",
        "    plot_df[col] = pd.to_numeric(plot_df[col], errors=\"coerce\")\n",
        "\n",
        "plot_df = plot_df.dropna()\n",
        "plot_df = plot_df.sort_values([\"rag_k\", \"chunk_size\"])\n",
        "\n",
        "# ----------------------------------\n",
        "# Annotation helper (robust)\n",
        "# ----------------------------------\n",
        "def annotate_from_df(ax, df, x_col, y_col, fmt, y_offset=6):\n",
        "    for _, row in df.iterrows():\n",
        "        if pd.notna(row[y_col]):\n",
        "            ax.annotate(\n",
        "                fmt.format(row[y_col]),\n",
        "                (row[x_col], row[y_col]),\n",
        "                textcoords=\"offset points\",\n",
        "                xytext=(0, y_offset),\n",
        "                ha=\"center\",\n",
        "                fontsize=9\n",
        "            )\n",
        "\n",
        "# ----------------------------------\n",
        "# Metrics to plot\n",
        "# ----------------------------------\n",
        "metrics = [\n",
        "    (\"Precision\", \"{:.3f}\"),\n",
        "    (\"Recall\", \"{:.3f}\"),\n",
        "    (\"F1 Score\", \"{:.3f}\"),\n",
        "    (\"NDCG@5\", \"{:.3f}\"),\n",
        "    (\"MRR\", \"{:.3f}\"),\n",
        "    (\"Processing Time\", \"{:.2f}s\"),\n",
        "]\n",
        "\n",
        "# ----------------------------------\n",
        "# Generate plots\n",
        "# ----------------------------------\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, (metric, fmt) in zip(axes, metrics):\n",
        "    for k, g in plot_df.groupby(\"rag_k\"):\n",
        "        ax.plot(\n",
        "            g[\"chunk_size\"],\n",
        "            g[metric],\n",
        "            marker=\"o\",\n",
        "            label=f\"k={int(k)}\"\n",
        "        )\n",
        "        annotate_from_df(ax, g, \"chunk_size\", metric, fmt)\n",
        "\n",
        "    ax.set_xlabel(\"Chunk Size (tokens)\")\n",
        "    ax.set_ylabel(metric)\n",
        "    ax.set_title(f\"{metric} vs Chunk Size\")\n",
        "    ax.set_xticks(sorted(plot_df[\"chunk_size\"].unique()))\n",
        "    ax.grid(True)\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6m7VpABPX_i"
      },
      "source": [
        "## Best-Performing Configurations\n",
        "\n",
        "Our experiments reveal **two distinct optima**, depending on whether the goal is maximizing ranking quality or prioritizing latency and robustness.\n",
        "\n",
        "###  Best Ranking Quality (Primary Winner)\n",
        "\n",
        "- **Chunk size:** 256  \n",
        "- **Retrieval depth (rag_k):** 8  \n",
        "- **Reranker top_n:** 2  \n",
        "\n",
        "This configuration achieves the **highest NDCG@5**, indicating the strongest ranking quality among all successful runs.  \n",
        "Despite using larger chunks, it remains **stable under context limits** when retrieval depth is kept moderate.\n",
        "\n",
        "---\n",
        "\n",
        "###  Best Latency‚ÄìStability Tradeoff\n",
        "\n",
        "- **Chunk size:** 128  \n",
        "- **Retrieval depth (rag_k):** 16  \n",
        "- **Reranker top_n:** 2  \n",
        "\n",
        "This configuration minimizes **end-to-end processing time** while avoiding prompt overflows.  \n",
        "Although ranking metrics are slightly lower than the primary winner, it provides a strong balance between **recall, stability, and runtime efficiency**.\n",
        "\n",
        "---\n",
        "\n",
        "### Key Insight\n",
        "\n",
        "There is **no single universally optimal RAG configuration**.  \n",
        "Instead, effective retrieval-first RAG systems must balance:\n",
        "\n",
        "- Ranking quality (NDCG@5, MRR)\n",
        "- Retrieval depth and semantic coverage\n",
        "- Context-length constraints\n",
        "- Runtime stability\n",
        "\n",
        "These results demonstrate why **controlled experimentation is essential** when deploying RAG systems under real-world constraints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "919bWReLPg9Z"
      },
      "source": [
        "## Role of RapidFire AI\n",
        "\n",
        "RapidFire AI enabled:\n",
        "- Parallel evaluation of RAG configurations\n",
        "- Clean separation of retrieval and evaluation logic\n",
        "- Interactive control over long-running experiments\n",
        "- Reproducible, customer-ready experimentation artifacts\n",
        "\n",
        "This mirrors how real AI teams test RAG pipelines before deployment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb3vJK7tPnao"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrates that effective RAG optimization requires:\n",
        "- Controlled experimentation\n",
        "- Awareness of context length constraints\n",
        "- Dataset-specific tuning\n",
        "\n",
        "Rather than maximizing retrieval depth blindly, we show that\n",
        "balanced configurations produce more reliable real-world systems.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "001a35e834c641ae9046aef17cc8b409": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d454cc0265446c9bc6aa2c0d39a24f8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1bebaedd7e3a45f3a9c92b7def9db33f",
            "value": "‚Äá3237/3237‚Äá[00:00&lt;00:00,‚Äá66540.69‚Äáexamples/s]"
          }
        },
        "0ec0c71ba59f49369d6ba23037894e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_645935857b124be2b7b2a7b615cd0710",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_36f3fc682e014b9cbb642109788c72d3",
            "value": "Filter:‚Äá100%"
          }
        },
        "1332661b33f24d9fb45b24680d2a9ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19bf31f253e94a0e93fa5f1ae940ea1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bebaedd7e3a45f3a9c92b7def9db33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cf4bdcc318e4c9b9696406f11749cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d454cc0265446c9bc6aa2c0d39a24f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2406dcf5f92844078684b9173ccb5c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29b9321854e84566b585f87c9890764c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "324cf6442b75486598675aef64e2f12d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "335d0d7401304b0289517459ac45542b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ec0c71ba59f49369d6ba23037894e6d",
              "IPY_MODEL_cef2edaff4b84bddb1a9c537e3b20a17",
              "IPY_MODEL_001a35e834c641ae9046aef17cc8b409"
            ],
            "layout": "IPY_MODEL_29b9321854e84566b585f87c9890764c"
          }
        },
        "33f05f43ea984b19bf9059e7192f98f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36f3fc682e014b9cbb642109788c72d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3da4baecc76f4181937b5f4b7915230e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bd8f6b015684f91be777f221cff393c",
              "IPY_MODEL_d28f9d6588bd4fc5b55df2ba8ea00188",
              "IPY_MODEL_c426608648eb4f5380de412b0cd79eda"
            ],
            "layout": "IPY_MODEL_54a90186865a4c5fbc53d65711b289fe"
          }
        },
        "49ef185a73ac4b1cab88e9e960349b93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "523a556e1fb34ecd804dd573c5ffcd72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f07bd392e0fa48ea96139ca5022af3b9",
              "IPY_MODEL_b4f3b2be0ef54c979b9fa1e74c38cf0d",
              "IPY_MODEL_ec7394f7361f4a36908105546bbf5513"
            ],
            "layout": "IPY_MODEL_9cfbb6117c474979a399218c22cadd58"
          }
        },
        "54a90186865a4c5fbc53d65711b289fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "550cba4136294729afb26f7c45ed4546": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fbab41b511f43e1938b56d599f099c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "645935857b124be2b7b2a7b615cd0710": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a9f421539e043ed9074ffee98f3e74c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81a3326eb6b4460fa6ddd2d0b630703f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2406dcf5f92844078684b9173ccb5c62",
            "value": "/content/datasets/nfcorpus.zip:‚Äá100%"
          }
        },
        "6bd8f6b015684f91be777f221cff393c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98342115463b4c448b44f6f6c4e41350",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e44b4c1f0b9e49a48b279718b9787a42",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá"
          }
        },
        "7be2dfff0eae469f84126c457930cf8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81a3326eb6b4460fa6ddd2d0b630703f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82f81071eaa84c50887cb179378b37ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98342115463b4c448b44f6f6c4e41350": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cfbb6117c474979a399218c22cadd58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d671fa97d544a0ae13ff7250c04c27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b4f3b2be0ef54c979b9fa1e74c38cf0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb875d10cdf747f5b066e77839afd543",
            "max": 3633,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82f81071eaa84c50887cb179378b37ca",
            "value": 3633
          }
        },
        "bda5d413f70c43f98bee52921429986e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be778bccf1ed4c3a80f981d8215baed5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c426608648eb4f5380de412b0cd79eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_550cba4136294729afb26f7c45ed4546",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1332661b33f24d9fb45b24680d2a9ef8",
            "value": "‚Äá3237/0‚Äá[00:00&lt;00:00,‚Äá68007.90‚Äáexamples/s]"
          }
        },
        "c7efceccb6164531a3a968c12c5f04cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be778bccf1ed4c3a80f981d8215baed5",
            "max": 2448432,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f30ec383c1804680a9bfb7e07c720700",
            "value": 2448432
          }
        },
        "cb345132c48a4771b03b760de37ccdc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb875d10cdf747f5b066e77839afd543": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cef2edaff4b84bddb1a9c537e3b20a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fbab41b511f43e1938b56d599f099c3",
            "max": 3237,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0ba8e0ae136468ba12ee980df98674a",
            "value": 3237
          }
        },
        "d28f9d6588bd4fc5b55df2ba8ea00188": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1d671fa97d544a0ae13ff7250c04c27",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cf4bdcc318e4c9b9696406f11749cfe",
            "value": 1
          }
        },
        "e0ba8e0ae136468ba12ee980df98674a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e44b4c1f0b9e49a48b279718b9787a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec7394f7361f4a36908105546bbf5513": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49ef185a73ac4b1cab88e9e960349b93",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cb345132c48a4771b03b760de37ccdc9",
            "value": "‚Äá3633/3633‚Äá[00:00&lt;00:00,‚Äá71097.20it/s]"
          }
        },
        "f07bd392e0fa48ea96139ca5022af3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bda5d413f70c43f98bee52921429986e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_33f05f43ea984b19bf9059e7192f98f3",
            "value": "100%"
          }
        },
        "f30ec383c1804680a9bfb7e07c720700": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa5c3b1a8f8a4a869ed36d0222f3d3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a9f421539e043ed9074ffee98f3e74c",
              "IPY_MODEL_c7efceccb6164531a3a968c12c5f04cf",
              "IPY_MODEL_fe1e5504170c4521a243b18bb28dab8e"
            ],
            "layout": "IPY_MODEL_19bf31f253e94a0e93fa5f1ae940ea1b"
          }
        },
        "fe1e5504170c4521a243b18bb28dab8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_324cf6442b75486598675aef64e2f12d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7be2dfff0eae469f84126c457930cf8c",
            "value": "‚Äá2.34M/2.34M‚Äá[00:00&lt;00:00,‚Äá2.86MiB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
